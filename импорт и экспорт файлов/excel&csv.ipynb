{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также вам известно, что, указав определенные значения параметров функции \n",
    "# read_csv(), \n",
    "можно считать данные из файла,\n",
    "в котором используется разделитель данных, \n",
    "отличный от запятой (sep),\n",
    " вместо десятичной точки используется другой символ (decimal), \n",
    " а также при считывании должно быть пропущено некоторое количество строк (skiprows). \n",
    "\n",
    "Такие данные обычно хранятся в текстовых файлах с расширением TXT. Этот тип файлов — источник данных,\n",
    " который легко расшифровывать и интерпретировать. Для чтения данных из файлов такого типа Pandas,  помимо функции read_csv(), предлагает и функцию read_table().\n",
    " Функция read_csv(), как вы уже знаете, загружает данные с разделителями из файла, URL-адреса, и в качестве разделителя\n",
    " по умолчанию используется запятая (символ). В документации эта функция описана как «Чтение данных из файла значений,\n",
    "  разделённых запятыми (CSV), в DataFrame».\n",
    "\n",
    "# Функция read_table() \n",
    "также загружает данные с разделителями из файла, URL-адреса, но в качестве разделителя по умолчанию \n",
    " используется символ табуляции ('\\t'). В документации эта функция описана как «Чтение данных из файл значений с разделителями \n",
    " в DataFrame».\n",
    "Данные функции используются похожим образом, и то, что в настоящий момент поддерживаются они обе, обусловлено тем, что\n",
    "  многие пользователи продолжают использовать функцию read_table(). Так, например, поиск на GitHub даёт более пятидесяти \n",
    " тысяч результатов по запросу \"pd.read_table\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd # Импорт библиотеки pandas — при выполнении последовательно всех примеров ниже, импорт библиотеки pandas выполняется один раз\n",
    "countries_data = pd.read_csv('data/countries.csv', sep=';') # Загружаем данные из файла в переменную, создавая объект DataFrame\n",
    "countries_data.to_csv('data/countries.txt', index=False, sep=' ') # Выгружаем данные из DataFrame в CSV-файл и сохраняем файл в папке data\n",
    "\n",
    "txt_df = pd.read_table('data/countries.txt', sep=' ', index_col=['country'])# Загружаем данные из файла в переменную, создавая объект DataFrame\n",
    "display(txt_df) # Выводим содержимое DataFrame на экран"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header\n",
    "Используя параметр header, при создании DataFrame мы учитываем наличие/отсутствие строки заголовков в исходном файле данных.\n",
    "\n",
    "Например, если при считывании данных из ранее сохранённого в папке data файла melb_data_ps.csv указать значение параметра header=None, то первая строка исходного файла не будет восприниматься как строка заголовка и будет отнесена к области данных DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "melb_data = pd.read_csv('data/melb_data.csv', header=None) # Загружаем данные из файла в переменную, создавая объект DataFrame\n",
    "display(melb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РЕШАЕМ ПРОБЛЕМУ С КОДИРОВКОЙ ИСХОДНЫХ ДАННЫХ\n",
    "\n",
    "При считывании файла и создании DataFrame может возникнуть проблема — при выводе на экран данные будут отображаться в виде нечитаемых символов. Это связано с кодировкой символов в исходном файле.\n",
    "Для решения проблемы выполним следующие действия:\n",
    "узнаем, какая кодировка символов используется в считываемом файле (для этого обратимся к субмодулю chardet.universaldetector библиотеки Universal Encoding Detector);\n",
    "при считывании файла и создании DataFrame будем использовать параметр encoding  —  указывает, какой тип кодировки символов используется в считываемом файле. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/ErrorEnCoding.csv', header=None ) # Считываем данные из файла с неизвестной кодировкой в переменную, создавая объект DataFrame\n",
    "display(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОПРЕДЕЛЯЕМ КОДИРОВКУ ФАЙЛА\n",
    "\n",
    "Приведённый ниже код поможет нам определить используемую кодировку в файле, степень достоверности, используемый язык."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chardet.universaldetector import UniversalDetector # Импортируем субмодуль chardet.universaldetector\n",
    "detector = UniversalDetector()\n",
    "with open('data/ErrorEnCoding.csv', 'rb') as fh:\n",
    "    for line in fh:\n",
    "        detector.feed(line)\n",
    "        if detector.done:\n",
    "            break\n",
    "detector.close()\n",
    "#С достоверностью примерно 84 % тип используемой в файле кодировки — koi8-r.\n",
    "#  Повторим считывание файла, используя полученные данные.\n",
    "# Создаем DataFrame из файла, явно указав кодировку символов, и выводим его содержимое на экран\n",
    "data=pd.read_csv('data/ErrorEnCoding.csv', encoding='koi8-r', header=None )\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЧТЕНИЕ ФАЙЛА ПО ССЫЛКЕ, ИСПОЛЬЗУЯ ФУНКЦИЮ READ_TABLE()\n",
    "\n",
    "Ранее вы уже считывали данные из файла melb_data.csv, который находится в свободном доступе в интернете, используя функцию read_csv(). Попробуем использовать функцию read_table(), указав в качестве разделителя данных запятую — ','."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18396"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_table('https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv', sep=',')\n",
    "display(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЧТЕНИЕ/ЗАПИСЬ АРХИВИРОВАННЫХ CSV-ФАЙЛОВ\n",
    "Механизм, используемый в функции read_csv(), позволяет проводить чтение текстового файла из архива, не распаковывая его. Функция read_csv() сама распознает архив и извлекает из него данные (работает практически со всеми zip-архивами). Есть ограничение — файл в zip-архиве должен быть один (если файлов в архиве несколько, то можно разархивировать файлы и работать с каждым вне архива. Подробнее об этом поговорим в юните Итоги).\n",
    "\n",
    "Ранее вы работали с датасетом students_performance.csv, упакованным в архив. Для работы с файлом вы предварительно проводили распаковку архива. Попробуем начать работу с файлом, не распаковывая его.\n",
    "\n",
    "✍️ Скачайте заархивированный датасет в CSV-формате students_performance.zip по ссылке  и скопируйте его в каталог data, не распаковывая архив.\n",
    "\n",
    "Используя функцию read_csv(), загрузите данные из заархивированного датасета  в переменную data() и выведите её содержимое на экран, используя приведённый ниже код:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/students_performance.zip')\n",
    "display(data)\n",
    "\n",
    "# В функции to_csv() предусмотрен механизм, позволяющий проводить упаковку CSV-файлов в zip-архив.\n",
    "#  Проделаем обратную операцию — данные из DataFrame data запишем в CSV-файл, упакуем полученный \n",
    "# файл в zip-архив «на лету» и сохраним полученный архив в папке data, выполнив следующий код:\n",
    "compression_opts = dict(method='zip', archive_name='out.csv') # Определяем параметры архивирования — метод сжатия, имя файл в архиве\n",
    "data.to_csv('data/out.zip', index=False, compression=compression_opts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# СЧИТЫВАНИЕ ДАННЫХ ИЗ ФАЙЛА EXCEL\n",
    "\n",
    "Подобно уже хорошо нам известной функции read_csv(), в pandas предусмотрена функция для удобного чтения XLS- и XLSX- файлов: read_excel() (англ. читать_Excel). Синтаксис обеих функций практически идентичен.\n",
    "\n",
    "✍️ Для примера попробуем открыть файл grades.xlsx, содержащий оценки студентов за прослушанные курсы. Скачайте его и скопируйте в папку data.\n",
    "\n",
    "Попробуем прочитать наш файл-пример. Для этого передадим в read_excel() путь к нему. Чтобы его открыть и сохранить данные в переменную grades, необходимо выполнить следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.read_excel('data/grades.xlsx')\n",
    "display(grades.head())\n",
    "\n",
    "#СЧИТЫВАНИЕ ДАННЫХ ИЗ ФАЙЛА EXCEL ПО ССЫЛКЕ\n",
    "\n",
    "#Если файл находится в открытом доступе по ссылке (например, на Google Диске или GitHub), его можно прочитать\n",
    " #и из интернета — для этого достаточно в функции read_excel() вместо пути до файла указать ссылку на файл. Например:\n",
    "\n",
    "data = pd.read_excel('https://github.com/asaydn/test/raw/master/january.xlsx')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основные параметры метода read_excel()\n",
    "\n",
    "io — первый параметр, в который мы передаём адрес файла, который хотим прочитать. Кроме адреса на диске, можно передавать адрес в интернете.\n",
    "sheet_name —  ссылка на лист в Excel-файле (возможные значения данного параметра: 0 — значение по умолчанию, загружается первый лист; 'Sheet1' — можно передать название листа; обычно листы называются 'SheetX', где X — номер листа, но могут использоваться и другие названия; [0, 1, 'Sheet3'] — список, содержащий номера или названия листов; в таком случае Pandas вернёт словарь, в котором ключами будут номера или названия листов, а значениями — их содержимое в виде DataFrame; None — если передать такое значение, то pandas прочитает все листы и вернёт их в виде словаря, как в предыдущем пункте).\n",
    "na_values — список значений, которые будут считаться пропусками ( ‘’, ‘#N/A’, ‘ N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’, ‘1.#IND’, ‘1.#QNAN’, ‘NA’, ‘NULL’, ‘NaN’, ‘n/a’, ‘nan’, ‘null’).\n",
    "Следует также учесть, что нормальное поведение pandas — это считывание значений (формулы из Excel-файла не считываются).\n",
    "\n",
    "Как упоминалось выше, один Excel-файл может включать в себя несколько листов, которые отображаются в разных вкладках (англ. sheet, рус. лист). Например, в нашем файле два листа — Maths и ML.\n",
    "\n",
    "По умолчанию в DataFrame читается информация из первого листа, однако read_excel()  позволяет выбрать, из какого именно листа загружать данные. Сделать это можно с помощью параметра sheet_name (рус. имя_листа). Например, чтобы прочесть данные из второго листа (ML) файла, выполним код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.read_excel('data/grades.xlsx', sheet_name='ML')\n",
    "display(grades.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ВЫГРУЗКА ДАННЫХ ИЗ DATAFRAME В EXCEL-ФАЙЛ\n",
    "\n",
    "После обработки данных (очистка, создание новых признаков и т. д.) методами и функциями pandas мы сталкиваемся с обратной задачей — сохранить данные из DataFrame в Excel-файл.\n",
    "\n",
    "Для этого в pandas есть функция to_excel() (рус. в_Excel), принцип работы которой очень схож с функцией to_csv():\n",
    "\n",
    " grades.to_excel('data/grades_new.xlsx') # Сохраняем данные из DataFrame grades в файл grades_new.xlsx в папке data\n",
    "В этом случае будет создан один лист с именем по умолчанию \"Sheet1\". Также мы сохраним и индекс — в данных будет находиться лишний столбец. Чтобы создать лист с определённым именем (например, Example) и не сохранять индекс, в метод  to_excel() необходимо передать параметры sheet_name='Example' и index=False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.to_excel('data/grades_new.xlsx', sheet_name='Example', index=False)\n",
    " # Сохраняем данные из DataFrame grades в файл grades_new.xlsx (на листе 'Example') в папке data\n",
    "\n",
    "\n",
    "ratings = pd.read_excel('data/ratings+movies.xlsx', sheet_name='ratings')         \n",
    "movies = pd.read_excel('data/ratings+movies.xlsx', sheet_name='movies')         \n",
    "joined = ratings.merge(movies, on='movieId', how='left')         \n",
    "joined.to_excel('joined.xlsx', sheet_name='JOINED', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dc41801cb733823d51f5a3b2beda62df20d3bf011ad730ae0b8a4522a55944d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
