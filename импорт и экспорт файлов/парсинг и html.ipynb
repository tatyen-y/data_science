{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотека requests\n",
    " Добавить страницу в мои закладки\n",
    "✍ В стандартной библиотеке Python для отправки веб-запросов существует функция urllib2, но большинство разработчиков используют стороннюю библиотеку requests (c англ. запросы), потому что её работа более стабильна, а созданный с её помощью код получается проще. Поэтому мы будем работать с библиотекой requests, а urllib2 рассматривать не будем.\n",
    "\n",
    "Познакомимся с библиотекой requests, решив простую задачу — получить значения курсов валют. Курс валют — полезная и регулярно обновляемая информация, но каждый раз в ручном режиме получать информацию о курсе интересующей валюты трудоёмко.\n",
    "\n",
    "Разработаем код, так называемый скрипт (англ. script, рус. сценарий), — небольшую программу, которая содержит последовательность действий для автоматического выполнения задачи.\n",
    "\n",
    "С помощью скрипта мы будем в удобном виде выгружать информацию по курсам валют с заранее выбранного сайта.\n",
    "\n",
    "Один из сайтов в интернете, на котором информация о курсах валют дублирует информацию с сайта Центрального Банка России, — ресурс Курсы валют ЦБ РФ в XML и JSON. На данном ресурсе информация о курсах валют представлена в разных форматах, в том числе и в структурированном JSON-формате, методы работы с которым мы изучили в одном из предыдущих модулей.\n",
    "\n",
    "Перед началом работы библиотеку requests потребуется установить. Например, в Jupyter Notebook это делается с помощью такой команды:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\tatye\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\tatye\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tatye\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tatye\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tatye\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2022.9.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как только библиотека установлена, импортируем её и отправим наш первый запрос к ресурсу Курсы валют ЦБ РФ в XML и JSON. Используем метод get() из библиотеки requests, передав ему соответствующий URL —  https://www.cbr-xml-daily.ru/daily_json.js:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests # Импортируем библиотеку requests\n",
    "url = 'https://www.cbr-xml-daily.ru/daily_json.js' # Определяем значение URL страницы для запроса\n",
    "response = requests.get(url) # Делаем GET-запрос к ресурсу и результат ответа сохраняем в переменной response\n",
    "print(response)\n",
    "#Код ответа в виде числовой переменной можно получить с помощью метода status_code:\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАБОТАЕМ С ОТВЕТОМ\n",
    "\n",
    "Мы сделали запрос и получили корректный ответ (код статуса — 200). Дальнейшую работу производим с результатом запроса к ресурсу Курсы валют ЦБ РФ в XML и JSON.\n",
    "\n",
    "?\n",
    "Как получить доступ ко всей информации, которую содержит ответ?\n",
    "\n",
    "Текст ответа хранится в атрибуте text. Выведем значение атрибута на экран и посмотрим на его содержимое:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n",
      "{'CharCode': 'EUR',\n",
      " 'ID': 'R01239',\n",
      " 'Name': 'Евро',\n",
      " 'Nominal': 1,\n",
      " 'NumCode': '978',\n",
      " 'Previous': 63.3008,\n",
      " 'Value': 63.3882}\n",
      "Чешских крон\n"
     ]
    }
   ],
   "source": [
    " # Выводим содержимое атрибута text переменной response на экран\n",
    "print(type(response))\n",
    "\n",
    "#Как правило, при работе над реальным проектом на этапе получения данных мы уже понимаем, с какими форматами\n",
    "#  данных нам придётся работать. На предлагаемом для работы ресурсе информация есть как в JSON-формате, так и в XML.\n",
    "#  По нашему запросу ресурс возвращает информацию в JSON-формате, однако в настоящий момент результат хранится как \n",
    "# единая строка. Проверить тип данных полученного ответа можно, воспользовавшись функцией type().\n",
    "#Для того чтобы удобно было работать с полученной информацией, нам необходимо преобразовать строку в словарь. \n",
    "# В объект ответа Response  из библиотеки requests уже встроен метод json() .\n",
    "#Импортируем функцию pprint(), применим к полученному ответу метод json() и выведем полученный результат на экран:\n",
    "from pprint import pprint # Импортируем функцию pprint()\n",
    "currencies = response.json() # Применяем метод json()\n",
    " # Выводим результат на экран)\n",
    "\n",
    "#Теперь данные находятся в словаре и можно легко получать необходимые значения.\n",
    "\n",
    "#Например, по ключу Valute мы можем обратиться к вложенному словарю, который \n",
    "#содержит информацию о мировых валютах. Выведем на экран, например, информацию о евро (EUR):\n",
    "pprint(currencies['Valute']['EUR'])\n",
    "print(currencies['Valute']['CZK']['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг сайтов\n",
    " Добавить страницу в мои закладки\n",
    "✍ Ресурс, с которым мы работали в предыдущем юните, возвращал ответ о текущем курсе валют в удобном, структурированном формате, из которого было легко извлечь необходимую информацию. Довольно часто для получения информации приходится обращаться напрямую к HTML-страницам.\n",
    "\n",
    "Для примера рассмотрим страницу, содержащую статью с информацией о присуждении Нобелевской премии по экономике в 2021 году, и попробуем извлечь из неё заголовок статьи, опубликованной на странице, дату публикации, а также текст статьи.\n",
    "\n",
    "Получить содержимое страницы в большинстве случаев несложно, гораздо труднее извлечь из HTML-кода нужную информацию.\n",
    "\n",
    "?\n",
    "Что собой представляет HTML?\n",
    "\n",
    "## ОСНОВЫ HTML\n",
    "\n",
    "HTML (англ. HyperText Markup Language, рус. язык гипертекстовой разметки) — стандартизированный язык разметки документов в интернете. Большинство веб-страниц содержат описание разметки на языке HTML. Язык HTML интерпретируется браузерами. Полученный в результате интерпретации текст отображается на экране монитора компьютера или мобильного устройства.\n",
    "\n",
    "HTML позволяет создавать макет страницы, разбивая её на блоки: мы можем поместить содержимое посередине страницы, сбоку и т. п.\n",
    "\n",
    "Кроме того, HTML используется для описания форматирования. Например, с его помощью мы можем указать, какая часть текста должна отображаться крупным шрифтом как заголовок, какая — курсивом, а какая — как обычный текст.\n",
    "\n",
    "HTML является близким родственником уже знакомого вам формата XML. Разметка на языке HTML делается с помощью так называемых тегов, которые помещаются в угловые скобки, и применяется к элементам, заключённым внутри них. Посмотрите на примеры:\n",
    "\n",
    "h2 Это заголовок второго уровня /h2\n",
    "div А это обычный текст /div\n",
    "У корректной HTML-страницы есть заголовок и тело страницы. В заголовке (в тегах head … /head)  размещается техническая информация, подключаются скрипты и стили. В теле body … /body находятся текст и данные, которые непосредственно отображаются на странице в браузере.\n",
    "\n",
    "Разметка небольшой страницы выглядит примерно так:\n",
    "\n",
    "\n",
    "Обратите внимание, что теги образуют иерархическую структуру, то есть одни теги расположены внутри других. В примере выше тег p … /p находится внутри тега body … /body.\n",
    "\n",
    "Кроме того, у тегов могут быть атрибуты, которые пишутся внутри открывающегося тега. Самые популярные атрибуты — это class и id:\n",
    "\n",
    "h1 id=\"big-title\"> Заголовок страницы /h1\n",
    "p class=\"red-back\"> Какой-то текст /p\n",
    "Изучение языка HTML находится вне рамок этого курса, но для того, чтобы собирать информацию с веб-страниц, нет необходимости хорошо знать HTML. Достаточно понимать, что:\n",
    "\n",
    "существуют теги с разными именами;\n",
    "у тегов бывают атрибуты, такие как class и id;\n",
    "теги образуют иерархическую структуру, то есть одни теги вложены в другие.\n",
    "ДОПОЛНИТЕЛЬНО\n",
    "\n",
    "Вы можете ознакомиться с информацией о HTML в справочнике, перейдя по ссылке.\n",
    "\n",
    "ПОЛУЧАЕМ СОДЕРЖИМОЕ ВЕБ-СТРАНИЦЫ\n",
    "\n",
    "Получим HTML-код интересующей нас страницы.\n",
    "\n",
    "Для этого отправим GET-запрос с помощью библиотеки requests и метода get() и посмотрим на текст ответа на наш запрос (как мы помним, он содержится в атрибуте text):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # Импортируем библиотеку requests\n",
    "url = 'https://nplus1.ru/news/2021/10/11/econobel2021' # Определяем адрес страницы\n",
    "response = requests.get(url)  # Выполняем GET-запрос\n",
    "print(response.text)  # Выводим содержимое атрибута text\n",
    "#Ответ содержит HTML-код страницы, к которой мы обратились.\n",
    "#В отличие от предыдущего примера, где ответ возвращался в JSON-формате, мы не можем так просто\n",
    "#  преобразовать HTML-код в словарь и извлечь необходимую нам информацию.\n",
    "#Для решения таких задач в Python существует специальная библиотека BeautifulSoup, о работе с которой\n",
    "#  мы поговорим в следующем юните."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотека BeautifulSoup\n",
    " Добавить страницу в мои закладки\n",
    "✍ Для поиска необходимых нам данных мы будем использовать библиотеку BeautifulSoup, которая позволяет по названию тегов и их атрибутов получать содержащийся в них текст.\n",
    "\n",
    "BeautifulSoup не является частью стандартной библиотеки, поэтому для начала её нужно установить. Например, в Jupyter Notebook это делается с помощью такой команды:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\tatye\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\tatye\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "<title>Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей</title>\n",
      "Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей\n"
     ]
    }
   ],
   "source": [
    "# Устанавливаем библиотеку BeautifulSoup\n",
    "!pip install beautifulsoup4 \n",
    "#После установки импортируем библиотеку в наш код:\n",
    "\n",
    "from bs4 import BeautifulSoup # Импортируем библиотеку BeautifulSoup\n",
    "#Теперь мы можем извлекать данные из любой веб-страницы.\n",
    "\n",
    "#Ранее мы уже получили содержимое страницы с помощью GET-запроса и сохранили информацию в переменной response , \n",
    "# теперь создадим объект BeautifulSoup с именем page, указывая в качестве параметра html.parser.\n",
    "\n",
    "#Для примера получим информацию o title (с англ. заголовок) — это строка, которая отображается на вкладке браузера:\n",
    "import requests # Импортируем библиотеку requests\n",
    "from bs4 import BeautifulSoup # Импортируем библиотеку BeautifulSoup\n",
    "url = 'https://nplus1.ru/news/2021/10/11/econobel2021' # Определяем адрес страницы\n",
    "response = requests.get(url) # Выполняем GET-запрос, содержимое ответа присваивается переменной response\n",
    "page = BeautifulSoup(response.text, 'html.parser') # Создаём объект BeautifulSoup, указывая html-парсер\n",
    "print(page.title) # Получаем тег title, отображающийся на вкладке браузера\n",
    "print(page.title.text) # Выводим текст из полученного тега, который содержится в атрибуте text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eсли при запросе к сайту, а затем при его разборе с помощью BeautifulSoup в тексте страницы не находится нужный тег, попробуйте вывести на печать пару тысяч символов текста страницы. Если там обнаружится нечто похожее на капчу, возможно, сайт посчитал вас роботом и отказывается выдавать содержимое. Чтобы получить его, попробуйте «притвориться» браузером при запросе из скрипта:\n",
    "\n",
    "requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "# ИЗВЛЕКАЕМ ЗАГОЛОВОК И ВРЕМЯ НАПИСАНИЯ СТАТЬИ\n",
    "\n",
    "Выполним поставленную ранее задачу: получить информацию о странице и извлечь заголовок статьи, опубликованной на этой странице, дату публикации, а также текст статьи.\n",
    "\n",
    "Предположим, что мы знаем, что в HTML-коде рассматриваемой нами страницы заголовок статьи заключён в тег h1 … /h1 (заголовок первого уровня).\n",
    "\n",
    "Тогда мы можем получить его текст с помощью метода find() (с англ. найти) объекта BeautifulSoup, передав ему название интересующего нас тега:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "print(page.find('h1').text) # Применяем метод find() к объекту и выводим результат на экран\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но как же узнать, в каких именно тегах заключена необходимая информация?\n",
    "\n",
    "Проще всего это сделать с помощью так называемого инструмента разработчика, который есть во всех современных браузерах. Покажем, как открыть данный инструмент на примере использования браузера Google Chrome.\n",
    "\n",
    "Устанавливаем курсор на элементе страницы (заголовок статьи), информацию о котором хотим получить, нажимаем на правую клавишу мыши и в выпадающем списке выбираем пункт «Просмотреть код элемента» или «Посмотреть код» в зависимости от браузера.\n",
    "\n",
    "В открывшемся окне инструмента разработчика видим, что информация о заголовке статьи заключена в теге h1 … /h1.\n",
    "Аналогично получим информации о теге, который содержит дату написания статьи, отображаемую в левом верхнем углу страницы.\n",
    "Итак, нам нужен тег <span> … </span>.\n",
    "\n",
    "Теперь получим данные из него с помощью уже известного метода find(), передав название нужного тега:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13:04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(page.find('span').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# НЕУНИКАЛЬНЫЕ ТЕГИ: ИЗВЛЕКАЕМ ТЕКСТ СТАТЬИ\n",
    "\n",
    "Теперь получим сам текст статьи. Как вы уже знаете, первым делом необходимо определить, в какой тег он заключён. Применим, как и ранее, инструмент разработчика. Метод find() нашёл первый из них, но это не то, что нам надо.\n",
    "\n",
    "Посмотрим на нашу страницу, используя инструмент разработчика, ещё раз. Можем заметить, что у искомого текста есть свой класс — n1_material text-18 :\n",
    "Передадим название класса в метод find() с помощью аргумента class_ и получим текст статьи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Премия Шведского национального банка по экономическим наукам памяти Альфреда Нобеля за 2021 год присуждена Дэвиду Карду (David Card) за его вклад в эмпирические исследования экономики рынка труда, а также Джошуа Энгристу (Joshua Angrist) и Гвидо Имбенсу (Guido Imbens) за их вклад в методологию анализа причинно-следственных связей. Прямая трансляция церемонии объявления лауреатов шла на официальном сайте Нобелевской премии.\n",
      "Премия Шведского национального банка по экономическим наукам памяти Альфреда Нобеля за 2021 год присуждена Дэвиду Карду (David Card) за его вклад в эмпирические исследования экономики рынка труда, а также Джошуа Энгристу (Joshua Angrist) и Гвидо Имбенсу (Guido Imbens) за их вклад в методологию анализа причинно-следственных связей. Прямая трансляция церемонии объявления лауреатов шла на официальном сайте Нобелевской премии.\n",
      "Премия Шведского национального банка по экономическим наукам памяти Альфреда Нобеля за 2021 год присуждена Дэвиду Карду (David Card) за его вклад в эмпирические исследования экономики рынка труда, а также Джошуа Энгристу (Joshua Angrist) и Гвидо Имбенсу (Guido Imbens) за их вклад в методологию анализа причинно-следственных связей. Прямая трансляция церемонии объявления лауреатов шла на официальном сайте Нобелевской премии.\n"
     ]
    }
   ],
   "source": [
    "print(page.find('div', class_='n1_material text-18').text)\n",
    "#В данном случае происходит поиск точного строкового значения class атрибута, т. е. выполнение строк кода\n",
    "#даст одинаковый результат.\n",
    "\n",
    "print(page.find('div', class_='n1_material').text)\n",
    "print(page.find('div', class_='n1_material text-18').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СБОР НЕСКОЛЬКИХ ЭЛЕМЕНТОВ: СОБИРАЕМ ВСЕ ССЫЛКИ НА СТРАНИЦЕ\n",
    "\n",
    "Рассмотрим ещё один сценарий: вы хотите собрать сразу несколько элементов со страницы. Например, представьте, что вы хотите получить названия всех языков программирования, упомянутых на странице в Wikipedia в статье про языки программирования.\n",
    "\n",
    "Можно заметить, что все названия языков программирования на этой странице связаны ссылками c соответствующими статьями о них. Таким образом, нам необходимо собрать все ссылки на странице. Для ссылок в HTML предусмотрен тег <a> … </a>. Попробуем использовать find():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a id=\"top\"></a>\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_programming_languages' # Задаём адрес ресурса\n",
    "response = requests.get(url) # Делаем GET-запрос к ресурсу\n",
    "page = BeautifulSoup(response.text, 'html.parser') # Создаём объект BeautifulSoup\n",
    "print(page.find('a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили только одну ссылку, хотя на странице их явно больше.\n",
    "\n",
    "Это происходит, потому что метод \n",
    "#### find() \n",
    "возвращает только первый подходящий элемент. Если требуется получить больше элементов, необходимо воспользоваться методом find_all() (с англ. найти все):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "['', 'Jump to navigation', 'Jump to search', 'Programming languagelists', 'Alphabetical', 'Categorical', 'Chronological', 'Generational', 'v', 't']\n"
     ]
    }
   ],
   "source": [
    "links = page.find_all('a') # Ищем все ссылки на странице и сохраняем в переменной links в виде списка\n",
    "print(len(links))\n",
    "# Не все ссылки соответствуют названиям языков программирования — страница содержит также «служебные» ссылки,\n",
    "#  такие, например, как Jump to navigation (с англ. Перейти к навигации) или Alphabetical (с англ. По алфавиту):\n",
    "\n",
    "print([link.text for link in links[0:10]]) # Выводим ссылки с 1 по 9 включительно"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dc41801cb733823d51f5a3b2beda62df20d3bf011ad730ae0b8a4522a55944d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
